# Prometheus Configuration for Docker Compose
# This configuration scrapes metrics from containerized services

global:
  scrape_interval: 15s      # How often to scrape targets
  evaluation_interval: 15s  # How often to evaluate rules

  # Attach these labels to any time series or alerts
  external_labels:
    monitor: 'neuroclima-docker'
    environment: 'production'

# Scrape configuration
scrape_configs:
  # Scrape Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
        labels:
          service: 'prometheus'

  # Scrape the NeuroClima Python Backend (Docker service name)
  - job_name: 'neuroclima-backend'
    scrape_interval: 10s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['server:8001']
        labels:
          service: 'neuroclima'
          component: 'backend'
          instance: 'docker'

  # Scrape GPU LLM Server Metrics
  - job_name: 'gpu-llm'
    scrape_interval: 10s
    metrics_path: '/metrics'
    static_configs:
      - targets: ['86.50.23.167:9100']
        labels:
          service: 'llm'
          component: 'gpu-server'
          instance: 'ollama-vm'
          gpu_type: 'nvidia'
