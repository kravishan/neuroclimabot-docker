# ============================================================================
# NEUROCLIMA DOCUMENT PROCESSOR - ENVIRONMENT CONFIGURATION
# ============================================================================
# Copy this file to .env and fill in your actual values
# Never commit the .env file to version control
# ============================================================================

# ----------------------------------------------------------------------------
# Application Settings
# ----------------------------------------------------------------------------
APP_NAME=NeuroClima Document Processor
APP_VERSION=7.0.0
DEBUG=False
LOG_LEVEL=INFO
HOST=0.0.0.0
PORT=5000

# ----------------------------------------------------------------------------
# Processing Configuration
# ----------------------------------------------------------------------------
MAX_CONCURRENT_TASKS=3

# ----------------------------------------------------------------------------
# MODEL PROVIDER SELECTION (Free vs Paid)
# ----------------------------------------------------------------------------
# Options: "free" (Ollama) or "paid" (OpenAI)
MODEL_PROVIDER=free

# When MODEL_PROVIDER=free, uses Ollama (local, no cost)
# When MODEL_PROVIDER=paid, uses OpenAI API (requires API key, incurs costs)

# ----------------------------------------------------------------------------
# OpenAI Configuration (for MODEL_PROVIDER=paid)
# ----------------------------------------------------------------------------
# OpenAI API Key (required when MODEL_PROVIDER=paid)
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI model for text generation and summarization
OPENAI_MODEL=gpt-4-turbo-preview

# OpenAI embedding model
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# OpenAI API timeout in MINUTES (will be converted to seconds)
OPENAI_TIMEOUT=2

# OpenAI API base URL (optional, for custom endpoints)
OPENAI_API_BASE=https://api.openai.com/v1

# OpenAI organization ID (optional)
OPENAI_ORGANIZATION=

# ----------------------------------------------------------------------------
# Ollama (LLM & Embeddings) - for MODEL_PROVIDER=free
# ----------------------------------------------------------------------------
# Ollama server URL
OLLAMA_API_URL=http://localhost:11434

# LLM model for text generation and summarization
OLLAMA_MODEL=mistral:7b

# Embedding model for vector generation
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# API timeout in MINUTES (will be converted to seconds)
OLLAMA_TIMEOUT=2

# ----------------------------------------------------------------------------
# MinIO (Object Storage)
# ----------------------------------------------------------------------------
# MinIO server endpoint (without http://)
MINIO_ENDPOINT=localhost:9000

# MinIO access credentials
ACCESS_KEY=minioadmin
SECRET_KEY=minioadmin

# Use HTTPS for MinIO connection
SECURE=False

# Processable buckets (comma-separated)
PROCESSABLE_BUCKETS=researchpapers,policy,news,scientificdata

# ----------------------------------------------------------------------------
# Milvus (Vector Database)
# ----------------------------------------------------------------------------
# Milvus server connection
MILVUS_HOST=localhost
MILVUS_PORT=19530

# Milvus authentication (leave empty if not required)
MILVUS_USER=
MILVUS_PASSWORD=

# Milvus database names
MILVUS_CHUNK_DATABASE=chunk_test5
MILVUS_SUMMARY_DATABASE=summary_test5

# Milvus collection mapping
# Format: MILVUS_COLLECTION_<BUCKET>=<collection_name>
MILVUS_COLLECTION_NEWS=News
MILVUS_COLLECTION_SCIENTIFICDATA=Scientific_Data
MILVUS_COLLECTION_POLICY=Policy
MILVUS_COLLECTION_RESEARCHPAPERS=Research_Papers

# ----------------------------------------------------------------------------
# LanceDB (GraphRAG Graph Storage)
# ----------------------------------------------------------------------------
# LanceDB storage path (local directory)
LANCEDB_PATH=./lancedb_graphrag

# Enable LanceDB for GraphRAG storage
ENABLE_LANCEDB_GRAPHRAG=True

# ----------------------------------------------------------------------------
# Unstructured API (Document Extraction)
# ----------------------------------------------------------------------------
# Unstructured API server URL
UNSTRUCTURED_API_URL=http://localhost:8000

# API timeout in MINUTES (will be converted to seconds)
UNSTRUCTURED_TIMEOUT=5

# ----------------------------------------------------------------------------
# VISION MODEL & IMAGE EXTRACTION
# ----------------------------------------------------------------------------
# Enable image extraction and description
ENABLE_IMAGE_EXTRACTION=True

# Vision model provider: "ollama" (llava, bakllava) or "openai" (gpt-4-vision)
VISION_MODEL_PROVIDER=ollama

# Ollama Vision Model (when VISION_MODEL_PROVIDER=ollama)
# Options: llava:13b, llava:7b, bakllava, llava-llama3
OLLAMA_VISION_MODEL=llava:13b

# OpenAI Vision Model (when VISION_MODEL_PROVIDER=openai)
OPENAI_VISION_MODEL=gpt-4-vision-preview

# Image extraction settings
EXTRACT_IMAGES_FROM_PDF=True
EXTRACT_IMAGES_FROM_DOCX=True
IMAGE_MIN_WIDTH=100
IMAGE_MIN_HEIGHT=100
IMAGE_MAX_SIZE_MB=10

# Image processing
RESIZE_IMAGES_FOR_VISION=True
MAX_IMAGE_DIMENSION=1024

# Replace images with descriptions in final output
REPLACE_IMAGES_WITH_DESCRIPTIONS=True

# ----------------------------------------------------------------------------
# CLIMATEGPT-7B MODEL (Advanced Summarization)
# ----------------------------------------------------------------------------
# Enable ClimateGPT-7B for high-quality abstractive summaries
# Model: https://huggingface.co/eci-io/climategpt-7b
USE_CLIMATEGPT=False

# Device to run ClimateGPT on ('auto', 'cuda', or 'cpu')
# 'auto' will automatically use GPU if available, otherwise CPU
CLIMATEGPT_DEVICE=auto

# Memory optimization (use one of these for large models)
CLIMATEGPT_8BIT=False
CLIMATEGPT_4BIT=False

# ----------------------------------------------------------------------------
# SCIENTIFIC DATA PROCESSING
# ----------------------------------------------------------------------------
# Enable specialized processing for scientific data files
ENABLE_SCIENTIFIC_DATA_PROCESSING=True

# Supported scientific data formats
SCIENTIFIC_DATA_FORMATS=csv,tsv,xlsx,xls,nc,netcdf,hdf5,h5,mat,parquet

# CSV/Excel processing
CSV_SAMPLE_ROWS=100
CSV_INCLUDE_STATISTICS=True
EXCEL_PROCESS_ALL_SHEETS=True

# NetCDF/HDF5 processing
NETCDF_EXTRACT_METADATA=True
NETCDF_SAMPLE_ARRAYS=True
NETCDF_MAX_ARRAY_SAMPLE=1000

# Scientific data chunking strategy
SCIENTIFIC_DATA_CHUNK_SIZE=5000
SCIENTIFIC_DATA_INCLUDE_SCHEMA=True
SCIENTIFIC_DATA_INCLUDE_STATISTICS=True

# Python libraries required:
# pandas, xarray, netCDF4, h5py, openpyxl, pyarrow

# ----------------------------------------------------------------------------
# GraphRAG Settings
# ----------------------------------------------------------------------------
# Enable Microsoft GraphRAG processing
ENABLE_MICROSOFT_GRAPHRAG=True

# GraphRAG workspace directories
GRAPHRAG_BASE_DIR=./graphrag_workspace
GRAPHRAG_TEMP_DIR=./graphrag_temp

# GraphRAG LLM Configuration
GRAPHRAG_API_KEY=not-needed
GRAPHRAG_LLM_MODEL=mistral:7b
GRAPHRAG_LLM_API_BASE=http://localhost:11434/v1
GRAPHRAG_LLM_TIMEOUT=3  # MINUTES (will be converted to seconds)
GRAPHRAG_LLM_TEMPERATURE=0.1
GRAPHRAG_LLM_MAX_TOKENS=4000

# GraphRAG Embedding Configuration
GRAPHRAG_EMBEDDING_MODEL=nomic-embed-text:latest
GRAPHRAG_EMBEDDING_API_BASE=http://localhost:11434/v1

# GraphRAG Processing Limits
GRAPHRAG_MAX_TEXT_LENGTH=50000
GRAPHRAG_CHUNK_SIZE=1200
GRAPHRAG_TIMEOUT=60  # MINUTES (will be converted to seconds)

# ----------------------------------------------------------------------------
# GraphRAG Advanced Features
# ----------------------------------------------------------------------------
# Prompt Tuning: Auto-generate optimized prompts for entity/relationship extraction
# Set to False by default - you can enable it later for better extraction quality
GRAPHRAG_ENABLE_PROMPT_TUNING=False
GRAPHRAG_PROMPT_TUNING_INPUT_DIR=./graphrag_prompt_tuning_input
GRAPHRAG_PROMPT_TUNING_OUTPUT_DIR=./graphrag_prompt_tuning_output

# Claims Extraction: Extract factual claims from documents
GRAPHRAG_ENABLE_CLAIMS=True
GRAPHRAG_CLAIM_EXTRACTION_ENABLED=True
GRAPHRAG_MAX_CLAIMS_PER_CHUNK=10

# Covariates Extraction: Extract time-series data, events, and contextual information
GRAPHRAG_ENABLE_COVARIATES=True
GRAPHRAG_COVARIATE_EXTRACTION_ENABLED=True

# Text Units: Store document chunks with vector embeddings
GRAPHRAG_ENABLE_TEXT_UNITS=True
GRAPHRAG_TEXT_UNIT_SIZE=300
GRAPHRAG_TEXT_UNIT_OVERLAP=100

# Entity/Relationship Embeddings: Generate vector embeddings for entities and relationships
GRAPHRAG_ENABLE_ENTITY_EMBEDDINGS=True
GRAPHRAG_ENABLE_RELATIONSHIP_EMBEDDINGS=False

# Vector Search Configuration
GRAPHRAG_VECTOR_SEARCH_ENABLED=True
GRAPHRAG_VECTOR_SIMILARITY_THRESHOLD=0.7
GRAPHRAG_VECTOR_TOP_K=20

# Community Detection Settings
GRAPHRAG_COMMUNITY_ALGORITHM=leiden
GRAPHRAG_COMMUNITY_MAX_LEVEL=3
GRAPHRAG_ENABLE_HIERARCHICAL_COMMUNITIES=True

# ----------------------------------------------------------------------------
# STP (Social Tipping Points) Settings
# ----------------------------------------------------------------------------
# Enable STP processing
ENABLE_STP=True

# STP Milvus Configuration
STP_MILVUS_DATABASE=mvp_stp_chunks_short
STP_MILVUS_COLLECTION=stp_documents_test

# STP Classifier Configuration
STP_CLASSIFIER_MODEL=models/onnx_exports/roBERTa_stp0.5.onnx
STP_MIN_CONFIDENCE=0.5

# STP Text Processing
STP_TEXT_CLEANING_ENABLED=True
STP_REPHRASING_ENABLED=True
STP_REPHRASE_MAX_WORDS=80
STP_QF_ENABLED=True

# STP Embedding Configuration
STP_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
STP_EMBEDDING_DIM=384

# STP Chunking Configuration
STP_MIN_CHUNK_TOKENS=200
STP_MAX_CHUNK_TOKENS=1500
STP_TARGET_CHUNK_TOKENS=800

# STP Timeout in MINUTES (will be converted to seconds)
STP_TIMEOUT=5

# ----------------------------------------------------------------------------
# Chunking Strategy Configuration (per bucket)
# ----------------------------------------------------------------------------
# News
CHUNKING_STRATEGY_NEWS=semantic
CHUNK_SIZE_NEWS=600
CHUNK_OVERLAP_NEWS=100

# Scientific Data
CHUNKING_STRATEGY_SCIENTIFICDATA=semantic
CHUNK_SIZE_SCIENTIFICDATA=800
CHUNK_OVERLAP_SCIENTIFICDATA=150

# Policy
CHUNKING_STRATEGY_POLICY=semantic
CHUNK_SIZE_POLICY=700
CHUNK_OVERLAP_POLICY=120

# Research Papers
CHUNKING_STRATEGY_RESEARCHPAPERS=semantic
CHUNK_SIZE_RESEARCHPAPERS=900
CHUNK_OVERLAP_RESEARCHPAPERS=150

# ----------------------------------------------------------------------------
# Summarization Configuration (per bucket)
# ----------------------------------------------------------------------------
# Abstractive summarization (LLM-based)
SUMMARIZATION_NEWS=abstractive
SUMMARIZATION_SCIENTIFICDATA=abstractive
SUMMARIZATION_POLICY=abstractive
SUMMARIZATION_RESEARCHPAPERS=abstractive

# ----------------------------------------------------------------------------
# Database Configuration
# ----------------------------------------------------------------------------
# SQLite database path for tracking
DATABASE_PATH=./document_tracker.db

# ----------------------------------------------------------------------------
# Security & Performance
# ----------------------------------------------------------------------------
# CORS allowed origins (comma-separated, use * for all)
CORS_ORIGINS=*

# API rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# Maximum file upload size (MB)
MAX_UPLOAD_SIZE_MB=100

# ----------------------------------------------------------------------------
# Logging Configuration
# ----------------------------------------------------------------------------
# Log file path (leave empty for console only)
LOG_FILE=

# Log format: json or text
LOG_FORMAT=text

# Log rotation (size in MB)
LOG_MAX_SIZE_MB=50
LOG_BACKUP_COUNT=3

# ============================================================================
# NOTES
# ============================================================================
# 1. ⏱️ TIMEOUT VALUES ARE IN MINUTES (NOT SECONDS)
#    - All timeout values in this file are in MINUTES
#    - The application automatically converts them to seconds
#    - Example: OLLAMA_TIMEOUT=2 means 2 minutes (120 seconds)
#
# 2. Required Services:
#    - Ollama: For LLM and embeddings
#    - MinIO: For object storage
#    - Milvus: For vector storage
#    - Unstructured API: For document extraction
#
# 3. Optional Features:
#    - GraphRAG: Set ENABLE_MICROSOFT_GRAPHRAG=True
#    - STP: Set ENABLE_STP=True
#
# 4. For production deployment:
#    - Change DEBUG to False
#    - Use strong credentials for MinIO and Milvus
#    - Configure proper CORS_ORIGINS
#    - Enable HTTPS for MinIO (SECURE=True)
#
# 5. Resource Requirements:
#    - Ollama: 8GB+ RAM recommended
#    - Milvus: 4GB+ RAM recommended
#    - GraphRAG: Additional 4GB+ RAM for processing
#
# 6. Recommended Timeout Values:
#    - Development: OLLAMA_TIMEOUT=2 (2 minutes)
#    - Production: OLLAMA_TIMEOUT=5 (5 minutes)
#    - Large Documents: GRAPHRAG_TIMEOUT=60 (60 minutes)
#    - Unstructured API: UNSTRUCTURED_TIMEOUT=5 (5 minutes)
#
# ============================================================================
